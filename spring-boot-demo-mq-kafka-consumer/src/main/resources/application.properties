
server.port=28081
##########【Kafka集群】##########
spring.kafka.bootstrap-servers=localhost:9092
#===============【初始化消费者配置】=================
# 默认的消费组ID
spring.kafka.consumer.properties.group.id=defaultConsumerGroup
# 是否自动提交offset
spring.kafka.consumer.enable-auto-commit=true
# 提交offset延时（接收到消息后多久提交offset）
spring.kafka.consumer.auto-commit-interval=1000
# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest：重置为分区中最小的offset
# latest：重置为分区中最新的offset（消费分区中新产生的数据）
# none：只要有一个分区不存在已提交的offset，就抛出异常
spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间（超过这个时间consumer没有发送心跳，就会触发rebalance操作）
spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=180000
# kafka提供的序列化和反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费端监听topic不存在时，项目启动会报错（关掉）
spring.kafka.listener.missing-topics-fatal=false
# 设置批量消费
#spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息
#spring.kafka.consumer.max-poll-records=50



